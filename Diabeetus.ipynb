{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "seed = 169\n",
    "np.random.seed(seed)\n",
    "\n",
    "dataset = pd.read_csv(\"https://archive.ics.uci.edu/ml/machine-learning-databases/pima-indians-diabetes/pima-indians-diabetes.data\", \n",
    "                      header=None).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.8\n"
     ]
    }
   ],
   "source": [
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   6.   ,  148.   ,   72.   , ...,    0.627,   50.   ,    1.   ],\n",
       "       [   1.   ,   85.   ,   66.   , ...,    0.351,   31.   ,    0.   ],\n",
       "       [   8.   ,  183.   ,   64.   , ...,    0.672,   32.   ,    1.   ],\n",
       "       ..., \n",
       "       [   5.   ,  121.   ,   72.   , ...,    0.245,   30.   ,    0.   ],\n",
       "       [   1.   ,  126.   ,   60.   , ...,    0.349,   47.   ,    1.   ],\n",
       "       [   1.   ,   93.   ,   70.   , ...,    0.315,   23.   ,    0.   ]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last column is 0/1 for no/yes of Diabetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(dataset[:,0:8], dataset[:,8],test_size=0.25, random_state=87)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use cross-entropy because it is a classification problem\n",
    "\n",
    "Activation functions combine the neuron inputs to produce an output. For example, a step function would mean a neuron fires (has a non-zero value) if the input values exceed a certain threshold. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(seed)\n",
    "my_first_nn = Sequential() # create model\n",
    "my_first_nn.add(Dense(units=10, input_dim=8, activation='relu')) # hidden layer\n",
    "my_first_nn.add(Dense(units=1, activation='sigmoid')) # output layer\n",
    "my_first_nn.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a single layer NN. <br/>\n",
    "Easy to build in Keras, initialize model then sequentially add layers. <br/>\n",
    "'input_dim = 8' refers to the number of features fed into the hidden layer <br/>\n",
    "This hidden layer has 10 neurons. <br/>\n",
    "The output layer only has 1 neuron because this is a binary classification problem. <br/>\n",
    "\n",
    "Activation functions are when a neuron 'fires' (has a non-zero value) <br/>\n",
    "- A step activation function means that it fires when the value exceeds a certain threshold\n",
    "- Here use a Sigmoid activation. which looks like a step function but has a smooth gradient\n",
    "    - Importantly, it is non linear which gives analog activation\n",
    "    - The curve is steep between -2 and 2, which means that small changes in X will create a large change in Y\n",
    "    - Therefore it will bring activations to either 'side' of the curve making it good for classifiers. \n",
    "    \n",
    "- adam refers to Adaptive Moment Estimation, an optimizer like Gradient Descent which the model uses to tunes the parameteres to minimize the training error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify filepath- this will write a new file for each epoch with the epoch number contained within the filename\n",
    "# filepath=\"nn_weights-{epoch:02d}.hdf5\"\n",
    "# checkpoint = keras.callbacks.ModelCheckpoint(filepath, monitor='val_acc', verbose=0, save_weights_only=False, save_best_only=False, mode='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
