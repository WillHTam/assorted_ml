{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://scikit-learn.org/stable/auto_examples/ensemble/plot_gradient_boosting_quantile.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (<tokenize>, line 32)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<tokenize>\"\u001b[0;36m, line \u001b[0;32m32\u001b[0m\n\u001b[0;31m    self.clf = XGBRegressor(\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import binom_test\n",
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "from xgboost.sklearn import XGBRegressor\n",
    "from functools import partial\n",
    "class XGBOOSTQUANTILE(BaseEstimator, RegressorMixin):\n",
    "    def __init__(self, quant_alpha,quant_delta,quant_thres,quant_var,\n",
    "    n_estimators = 100,max_depth = 3,reg_alpha = 5.,reg_lambda=1.0,gamma=0.5):\n",
    "        self.quant_alpha = quant_alpha\n",
    "        self.quant_delta = quant_delta \n",
    "        self.quant_thres = quant_thres \n",
    "        self.quant_var = quant_var \n",
    "        #xgboost parameters \n",
    "        self.n_estimators = n_estimators \n",
    "        self.max_depth = max_depth \n",
    "        self.reg_alpha= reg_alpha \n",
    "        self.reg_lambda = reg_lambda \n",
    "        self.gamma = gamma \n",
    "        #keep xgboost estimator in memory \n",
    "        self.clf = None \n",
    "    def fit(self, X, y): \n",
    "        def quantile_loss(y_true, y_pred,_alpha,_delta,_threshold,_var): \n",
    "            x = y_true - y_pred \n",
    "            grad = (x<(_alpha-1.0)*_delta)*(1.0-_alpha)- ((x>=(_alpha-1.0)*_delta)&\n",
    "                                    (x<_alpha*_delta) )*x/_delta-_alpha*(x>_alpha*_delta) \n",
    "            hess = ((x>=(_alpha-1.0)*_delta)& (x<_alpha*_delta) )/_delta \n",
    "            _len = np.array([y_true]).size \n",
    "            var = (2*np.random.randint(2, size=_len)-1.0)*_var \n",
    "            grad = (np.abs(x)<_threshold )*grad - (np.abs(x)>=_threshold )*var \n",
    "            hess = (np.abs(x)<_threshold )*hess + (np.abs(x)>=_threshold ) \n",
    "            return grad, hess \n",
    "         self.clf = XGBRegressor(\n",
    "         objective=partial( quantile_loss,\n",
    "                            _alpha = self.quant_alpha,\n",
    "                            _delta = self.quant_delta,\n",
    "                            _threshold = self.quant_thres,\n",
    "                            _var = self.quant_var), \n",
    "                            n_estimators = self.n_estimators,\n",
    "                            max_depth = self.max_depth,\n",
    "                            reg_alpha =self.reg_alpha, \n",
    "                            reg_lambda = self.reg_lambda,\n",
    "                            gamma = self.gamma )\n",
    "        Â self.clf.fit(X,y) \n",
    "         return self \n",
    "    def predict(self, X): \n",
    "        y_pred = self.clf.predict(X) \n",
    "        return y_pred \n",
    "    def score(self, X, y): \n",
    "        y_pred = self.clf.predict(X) \n",
    "        score = (self.quant_alpha-1.0)*(y-y_pred)*(y<y_pred)+self.quant_alpha*(y-y_pred)* (y>=y_pred) \n",
    "        score = 1./np.sum(score) \n",
    "        return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(1)\n",
    "def f(x):\n",
    "    \"\"\"The function to predict.\"\"\"\n",
    "    return x * np.sin(x)\n",
    "#----------------------------------------------------------------------\n",
    "# First the noiseless case\n",
    "X = np.atleast_2d(np.random.uniform(0, 10.0, size=100)).T\n",
    "X = X.astype(np.float32)\n",
    "# Observations\n",
    "y = f(X).ravel()\n",
    "dy = 1.5 + 1.0 * np.random.random(y.shape)\n",
    "noise = np.random.normal(0, dy)\n",
    "y += noise\n",
    "y = y.astype(np.float32)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
